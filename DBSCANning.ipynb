{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DBSCANning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPwrjU3Ii2NZqz5szjyuKwT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zernach/CS-Unit-1-Project/blob/master/DBSCANning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_yfCuUGyUm8",
        "colab_type": "text"
      },
      "source": [
        "# Part 1 —— Defining functions for DBSCAN using only numpy and base python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7cDzcRhx9-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def MyDBSCAN(x, eps, MinPts):\n",
        "    \"\"\"\n",
        "    Cluster the dataset `x` using the DBSCAN algorithm.\n",
        "    \n",
        "    MyDBSCAN takes a dataset `x` (a list of vectors), a threshold distance\n",
        "    `eps`, and a required number of points `MinPts`.\n",
        "    \n",
        "    It will return a list of cluster labels. The label -1 means noise, and then\n",
        "    the clusters are numbered starting from 1.\n",
        "    \"\"\"\n",
        " \n",
        "    # This list will hold the final cluster assignment for each point in x.\n",
        "    # There are two reserved values:\n",
        "    #    -1 - Indicates a noise point\n",
        "    #     0 - Means the point hasn't been considered yet.\n",
        "    # Initially all labels are 0.    \n",
        "    labels = [0]*len(x)\n",
        "\n",
        "    # C is the ID of the current cluster.    \n",
        "    C = 0\n",
        "    \n",
        "    # This outer loop is just responsible for picking new seed points--a point\n",
        "    # from which to grow a new cluster.\n",
        "    # Once a valid seed point is found, a new cluster is created, and the \n",
        "    # cluster growth is all handled by the 'expandCluster' routine.\n",
        "    \n",
        "    # For each point P in the Dataset D...\n",
        "    # ('P' is the index of the datapoint, rather than the datapoint itself.)\n",
        "    for P in range(0, len(x)):\n",
        "    \n",
        "        # Only points that have not already been claimed can be picked as new \n",
        "        # seed points.    \n",
        "        # If the point's label is not 0, continue to the next point.\n",
        "        if not (labels[P] == 0):\n",
        "           continue\n",
        "        \n",
        "        # Find all of P's neighboring points.\n",
        "        NeighborPts = regionQuery(x, P, eps)\n",
        "        \n",
        "        # If the number is below MinPts, this point is noise. \n",
        "        # This is the only condition under which a point is labeled \n",
        "        # NOISE--when it's not a valid seed point. A NOISE point may later \n",
        "        # be picked up by another cluster as a boundary point (this is the only\n",
        "        # condition under which a cluster label can change--from NOISE to \n",
        "        # something else).\n",
        "        if len(NeighborPts) < MinPts:\n",
        "            labels[P] = -1\n",
        "        # Otherwise, if there are at least MinPts nearby, use this point as the \n",
        "        # seed for a new cluster.    \n",
        "        else:\n",
        "           C += 1\n",
        "           growCluster(x, labels, P, NeighborPts, C, eps, MinPts)\n",
        "    \n",
        "    # All data has been clustered!\n",
        "    return labels\n",
        "\n",
        "\n",
        "def growCluster(x, labels, P, NeighborPts, C, eps, MinPts):\n",
        "\n",
        "    # Assign the cluster label to the seed point.\n",
        "    labels[P] = C\n",
        "    \n",
        "    # Look at each neighbor of P (neighbors are referred to as Pn). \n",
        "    # NeighborPts will be used as a FIFO queue of points to search--that is, it\n",
        "    # will grow as we discover new branch points for the cluster. The FIFO\n",
        "    # behavior is accomplished by using a while-loop rather than a for-loop.\n",
        "    # In NeighborPts, the points are represented by their index in the original\n",
        "    # dataset.\n",
        "    i = 0\n",
        "    while i < len(NeighborPts):    \n",
        "        \n",
        "        # Get the next point from the queue.        \n",
        "        Pn = NeighborPts[i]\n",
        "       \n",
        "        # If Pn was labelled NOISE during the seed search, then we\n",
        "        # know it's not a branch point (it doesn't have enough neighbors), so\n",
        "        # make it a leaf point of cluster C and move on.\n",
        "        if labels[Pn] == -1:\n",
        "           labels[Pn] = C\n",
        "        \n",
        "        # Otherwise, if Pn isn't already claimed, claim it as part of C.\n",
        "        elif labels[Pn] == 0:\n",
        "            # Add Pn to cluster C (Assign cluster label C).\n",
        "            labels[Pn] = C\n",
        "            \n",
        "            # Find all the neighbors of Pn\n",
        "            PnNeighborPts = regionQuery(x, Pn, eps)\n",
        "            \n",
        "            # If Pn has at least MinPts neighbors, it's a branch point!\n",
        "            # Add all of its neighbors to the FIFO queue to be searched. \n",
        "            if len(PnNeighborPts) >= MinPts:\n",
        "                NeighborPts = NeighborPts + PnNeighborPts\n",
        "            # If Pn *doesn't* have enough neighbors, then it's a leaf point.\n",
        "            # Don't queue up it's neighbors as expansion points.\n",
        "            #else:\n",
        "                # Do nothing                \n",
        "                #NeighborPts = NeighborPts               \n",
        "        \n",
        "        # Advance to the next point in the FIFO queue.\n",
        "        i += 1        \n",
        "    \n",
        "    # We've finished growing cluster C!\n",
        "\n",
        "\n",
        "def regionQuery(x, P, eps):\n",
        "    \n",
        "    neighbors = []\n",
        "    \n",
        "    # For each point in the dataset...\n",
        "    for Pn in range(0, len(x)):\n",
        "        \n",
        "        # If the distance is below the threshold, add it to the neighbors list.\n",
        "        if np.linalg.norm(x[P] - x[Pn]) < eps:\n",
        "           neighbors.append(Pn)\n",
        "            \n",
        "    return neighbors"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpRVr9pQyoiy",
        "colab_type": "text"
      },
      "source": [
        "# Part 2 —— Download dataset for testing two different DBSCAN's (and import libraries)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4fLjUVSzlzQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets.samples_generator import make_blobs\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "\n",
        "points = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/points.csv')\n",
        "points = StandardScaler().fit_transform(points)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWTEJNs5_l6v",
        "colab_type": "text"
      },
      "source": [
        "# Part 3 —— Run my DBSCAN and sklearn's DBSCAN, and then compare results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxRtcqqNyoWd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9adc15c9-0a36-4c9e-bb41-88edb539d33b"
      },
      "source": [
        "###############################################################################\n",
        "# My implementation of DBSCAN\n",
        "print('Running my implementation...')\n",
        "my_labels = MyDBSCAN(points, eps=0.3, MinPts=10)\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "# Scikit-learn implementation of DBSCAN\n",
        "print('Runing scikit-learn implementation...')\n",
        "db = DBSCAN(eps=0.3, min_samples=10).fit(points)\n",
        "skl_labels = db.labels_\n",
        "\n",
        "# Scikit learn uses -1 to for NOISE, and starts cluster labeling at 0. I start\n",
        "# numbering at 1, so increment the skl cluster numbers by 1.\n",
        "for i in range(0, len(skl_labels)):\n",
        "    if not skl_labels[i] == -1:\n",
        "        skl_labels[i] += 1\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "# Compare Results from two Implementations\n",
        "\n",
        "num_disagree = 0\n",
        "\n",
        "# Go through each label and make sure they match (print the labels if they \n",
        "# don't)\n",
        "for i in range(0, len(skl_labels)):\n",
        "    if not skl_labels[i] == my_labels[i]:\n",
        "        print('Scikit learn:', skl_labels[i], 'mine:', my_labels[i])\n",
        "        num_disagree += 1\n",
        "\n",
        "if num_disagree == 0:\n",
        "    print('PASS - All labels match!')\n",
        "else:\n",
        "    print('FAIL -', num_disagree, 'labels don\\'t match.')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running my implementation...\n",
            "Runing scikit-learn implementation...\n",
            "PASS - All labels match!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdLTHT_D0C6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}